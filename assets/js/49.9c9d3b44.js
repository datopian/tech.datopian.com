(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{414:function(t,e,a){"use strict";a.r(e);var o=a(18),r=Object(o.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"data-flow-and-factory"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#data-flow-and-factory"}},[t._v("#")]),t._v(" Data Flow and Factory")]),t._v(" "),a("p",[t._v("A Data Flow is a work"),a("em",[t._v("flow")]),t._v(" or processing "),a("em",[t._v("flow")]),t._v(" for transforming or analysing data. A Factory is the system for creating and orchestrating these flows.")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("Objects\n\nRow\n  File\n    Dataset\n\nTransformations\n\nOperator\n  Pipeline\n    Flow \n")])])]),a("p",[t._v("NTS")]),t._v(" "),a("ul",[a("li",[t._v("A factory could be a (DA)G of flows b/c could be dependencies between them … e.g. run ComputeKeyMetrics only after all other flows have run …")]),t._v(" "),a("li",[t._v("But not always like that: flows can be completely independent.")])]),t._v(" "),a("h2",{attrs:{id:"features-job-stories"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#features-job-stories"}},[t._v("#")]),t._v(" Features (Job Stories)")]),t._v(" "),a("p",[t._v("As a Data Engineer i want to build data pipeline / flow quickly so that I can get hacking …")]),t._v(" "),a("ul",[a("li",[t._v("Don’t want massive fancy system")]),t._v(" "),a("li",[t._v("Something i can get started in 5m with")]),t._v(" "),a("li",[t._v("But is extensible")])]),t._v(" "),a("h2",{attrs:{id:"domain-model"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#domain-model"}},[t._v("#")]),t._v(" Domain Model")]),t._v(" "),a("p",[t._v("A Processor is a single operator on a unit of data e.g. a row (or a file).")]),t._v(" "),a("p",[t._v("A (Data) Flow is a DAG of processors starting from one or more sources and ending in one or more sinks. Note the simple case of a linear flow is very common.")]),t._v(" "),a("p",[t._v("A (Data) Factory consists of one or more flows")]),t._v(" "),a("h2",{attrs:{id:"key-components"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key-components"}},[t._v("#")]),t._v(" Key Components")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("      Factory - Runners, SaaS platform etc\n\ndatapackage-pipelines -> (dataflows-server / dataflows-runner)\ndataflows-cli : generators, hello-world, 'init', 'run'\ngoodtables.io\n\"blueprints\": standard setups for a factory (auto-guessed?)\n\n            DataFlows: Flow Libs\n\ndataflows : processor definition and chaining\nprocessors-library: stdlib, user contributed items [dataflows-load-csv]\n\n            Data Package Libs\n\ndata.py, DataPackage-py, GoodTables, ...\ntabulator, tableschema\n")])])]),a("p",[t._v("Factory =>  Assembly, Production Lines, Processors/Tasks")]),t._v(" "),a("p",[t._v("Pipelines => Factory, Flows           , Processors/Tasks")]),t._v(" "),a("h2",{attrs:{id:"our-work"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#our-work"}},[t._v("#")]),t._v(" Our work")]),t._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"http://www.dataflows.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://www.dataflows.org/"),a("OutboundLink")],1),t._v(" - new system Adam + Rufus designed in spring 2018 and Adam led development on\n"),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/datahq/dataflows",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/datahq/dataflows"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/datahq/dataflows/blob/master/TUTORIAL.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/datahq/dataflows/blob/master/TUTORIAL.md"),a("OutboundLink")],1)]),t._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/datahq/dataflows/blob/master/PROCESSORS.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/datahq/dataflows/blob/master/PROCESSORS.md"),a("OutboundLink")],1)])])]),t._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/datopian/dataflow-demo",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/datopian/dataflow-demo"),a("OutboundLink")],1),t._v(" - Rufus outline on a very simple tool from April 2018")]),t._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/datopian/factory",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/datopian/factory"),a("OutboundLink")],1),t._v(" - "),a("a",{attrs:{href:"http://datahub.io",target:"_blank",rel:"noopener noreferrer"}},[t._v("datahub.io"),a("OutboundLink")],1),t._v(" Factory “The service is responsible for running the flows for datasets that are frequently updated and maintained by Datahub. Service is using Datapackage Pipelines is a framework for declarative stream-processing of tabular data, and DataFlows to run the flows through pipelines to process the datasets.”")])]),t._v(" "),a("h3",{attrs:{id:"faqs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#faqs"}},[t._v("#")]),t._v(" FAQs")]),t._v(" "),a("ul",[a("li",[t._v("how is this different from data package pipelines\n"),a("ul",[a("li",[t._v("No need for yaml files")]),t._v(" "),a("li",[t._v("All processing code can be written in a single Python file")]),t._v(" "),a("li",[t._v("Can be combined with other Python code")]),t._v(" "),a("li",[t._v("Runs in one process (dpp uses multiple processes)")])])]),t._v(" "),a("li",[t._v("how do i find processors\n"),a("ul",[a("li",[t._v("Quite a lot of modification processors exist (i.e. modify the data)")]),t._v(" "),a("li",[t._v("A few dumpers exist (file, zip, sql-db, s3, …)")]),t._v(" "),a("li",[t._v("One loader atm (but we’re planning to add more)")]),t._v(" "),a("li",[t._v("–> need to think of registry (perhaps README is not a good place for that?)")])])]),t._v(" "),a("li",[t._v("how do i create processors\n"),a("ul",[a("li",[t._v("Tutorial covers this")])])]),t._v(" "),a("li",[t._v("How do I do debugging …")])]),t._v(" "),a("h3",{attrs:{id:"how-is-this-different-from-x"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#how-is-this-different-from-x"}},[t._v("#")]),t._v(" How is this different from X?")]),t._v(" "),a("p",[t._v("Key points are:")]),t._v(" "),a("ul",[a("li",[t._v("Simple")]),t._v(" "),a("li",[t._v("Quick")]),t._v(" "),a("li",[t._v("Lightweight")])]),t._v(" "),a("p",[t._v("Different from X")]),t._v(" "),a("ul",[a("li",[t._v("Luigi & Airflow\n"),a("ul",[a("li",[t._v("These are task runners - managing a dependency graph between 1000s of tasks.")]),t._v(" "),a("li",[t._v("Neither of them focus on actual data processing and are not a data streaming solution. Tasks do not move data from one to the other.")])])]),t._v(" "),a("li",[t._v("Nifi\n"),a("ul",[a("li",[t._v("Server based, Java, XML - not really suitable for quick prototyping")])])]),t._v(" "),a("li",[t._v("Cascading\n"),a("ul",[a("li",[t._v("Only Java support")])])]),t._v(" "),a("li",[t._v("Bubbles "),a("a",{attrs:{href:"http://bubbles.databrewery.org/documentation.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://bubbles.databrewery.org/documentation.html"),a("OutboundLink")],1),t._v(" - "),a("a",{attrs:{href:"https://www.slideshare.net/Stiivi/data-brewery-2-data-objects",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.slideshare.net/Stiivi/data-brewery-2-data-objects"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("mETL "),a("a",{attrs:{href:"https://github.com/ceumicrodata/mETL",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/ceumicrodata/mETL"),a("OutboundLink")],1),t._v(" mito ETL (yaml config files)")])])])}),[],!1,null,null,null);e.default=r.exports}}]);